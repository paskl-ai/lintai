# Lintai ğŸ›¡ï¸ğŸ¤–

**Lintai** is an experimental **AI-aware static-analysis tool** that spots _LLM-specific_ security bugs (prompt-injection, insecure output, data leakage â€¦) long before they ship.

| Why Lintai?                                                                              | What it does                                                                                                                        |
| ---------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| Traditional SAST canâ€™t â€œseeâ€ how you build prompts, stream completions or store vectors. | Lintai walks your AST, tags every AI sink (OpenAI, Anthropic, LangChain, â€¦), follows wrapper functions & asks an LLM to judge risk. |

> **Requires Python â‰¥ 3.10**

---

## âœ¨ Key features

- **Two analysis commands**
  - `lintai scan <path>` â€“ run all detectors, emit JSON (incl. _llm_usage_ summary)
  - `lintai ai-inventory <path>` â€“ list every AI call + wrapper chain
- **Browser UI** `lintai ui` â€“ FastAPI backend, plug-in React/Cytoscape frontend
- **LLM-usage budget** â€“ hard caps on requests / tokens / cost with live report
  `LINTAI_MAX_LLM_TOKENS  LINTAI_MAX_LLM_COST_USD  LINTAI_MAX_LLM_REQUESTS`
- Modular detector registry (`entry_points`)
- OWASP LLM Top-10 & MITRE ATT&CK baked in
- DSL for custom rules
- CI-friendly JSON / (soon) SARIF output

---

## ğŸš€ Quick start

### 1 Â· Install

```bash
# end users
pip install lintai

# full dev experience (tests, UI)
pip install -e ".[dev,ui]"
```

Enable LLM-backed checks:

```bash
pip install "lintai[openai]"      # or  [anthropic]  [gemini]  [cohere]
```

### 2 Â· Configure

```bash
# .env  (see env.sample)
OPENAI_API_KEY=sk-...
LINTAI_MAX_LLM_TOKENS=50_000
LINTAI_MAX_LLM_COST_USD=10
```

`lintai` auto-loads `.env` (no override of real env-vars).

### 3 Â· Run

```bash
lintai scan src/
lintai ai-inventory src/ --ai-call-depth 4
```

### 4 Â· Launch UI (optional)

```bash
lintai ui                  # http://localhost:8501/api/docs  (REST)
yarn -C lintai/ui/frontend start   # React dev-server on :5173
```

---

## ğŸ”§ Common flags

| Flag              | Description                              |
| ----------------- | ---------------------------------------- |
| `-l DEBUG`        | Verbose logging                          |
| `--ruleset <dir>` | Load custom YAML/JSON rules              |
| `--output <file>` | Write full JSON report instead of stdout |

---

## ğŸ§ª Sample `scan` output

```json
{
  "llm_usage": {
    "tokens_used": 3544,
    "usd_used": 0.11,
    "requests": 6,
    "limits": { "tokens": 50000, "usd": 10, "requests": 500 }
  },
  "findings": [
    {
      "owasp_id": "LLM01",
      "severity": "blocker",
      "location": "services/chat.py:57",
      "message": "User-tainted f-string used in prompt",
      "fix": "Wrap variable in escape_braces()"
    }
  ]
}
```

---

## ğŸ”¬ How LLM detectors work

Some rules send the **full function source** to an LLM and expect one-line JSON back:

```bash
export LINTAI_LLM_PROVIDER=anthropic
export ANTHROPIC_API_KEY=sk-...
```

Budgets are enforced _before_ the call and itemised afterwards.

---

## ğŸ“¦ Directory layout

lintai/
â”œâ”€ cli.py â† Typer entry-point
â”œâ”€ ui/ â† FastAPI backend + React frontend stub
â”œâ”€ engine/ â† AST walker & AI-call analysis
â”œâ”€ detectors/ â† Static & LLM-powered rules
â”œâ”€ dsl/ â† Custom rule loader
â””â”€ core/ â† Finding model, token-budget manager â€¦

---

## ğŸŒ REST API cheat-sheet

| Method & path                | Body / Params      | Purpose                             |
| ---------------------------- | ------------------ | ----------------------------------- |
| `GET  /api/health`           | â€“                  | Liveness probe                      |
| `GET  /api/config`           | â€“                  | Read current config                 |
| `POST /api/config`           | `ConfigModel` JSON | Update settings (path, depth â€¦)     |
| `POST /api/scan`             | multipart files    | Run detectors on uploaded code      |
| `POST /api/inventory`        | `path=<dir>`       | Inventory run on server-side folder |
| `GET  /api/runs`             | â€“                  | List all runs + status              |
| `GET  /api/results/{run_id}` | â€“                  | Fetch scan / inventory report       |

OpenAPI docs auto-generated at **`/api/docs`**.

---

## ğŸ“º Roadmap

- SARIF & GitHub-Actions template
- VS Code extension (uses above REST)
- Live taint-tracking
- JavaScript/TypeScript support

---

## ğŸ¤ Contributing

1. **Star** the repo â­
2. `git checkout -b feat/my-fix`
3. `pytest -q` (all green)
4. Open a PR â€“ or a draft PR early
5. See `CONTRIBUTING.md`

Created by **Harsh Parandekar** â€” [LinkedIn](https://linkedin.com/in/hparandekar)
Licensed under **Apache 2.0**
